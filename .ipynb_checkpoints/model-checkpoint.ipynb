{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "with open('./TrainingData/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "measurements = []\n",
    "for line in lines:\n",
    "    for i in range(3):\n",
    "        source_path = line[i]\n",
    "        #filename = source_path.split(\"/\")[-1]\n",
    "        #current_path = \"./TrainingDataTesting/IMG/\" + filename\n",
    "        #image = cv2.imread(source_pathaawawwwwwwwwaw)\n",
    "        images.append(source_path)\n",
    "        measurement = float(line[3])\n",
    "        if i == 0:\n",
    "            measurements.append(measurement)\n",
    "        if i == 1:\n",
    "            measurements.append(measurement+0.2)\n",
    "        if i == 2:\n",
    "            measurements.append(measurement-0.2)\n",
    "X = np.array(images)\n",
    "y = np.array(measurements)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generator(X_samples, y_samples, batch_size=32):\n",
    "    num_samples = len(X_samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        #shuffle(X)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_X_samples = X_samples[offset:offset+batch_size]\n",
    "            batch_y_samples = y_samples[offset:offset+batch_size]\n",
    "            images = []\n",
    "            angles = []\n",
    "            for x,y in zip(batch_X_samples,batch_y_samples):\n",
    "                \n",
    "                image = cv2.imread(x)\n",
    "                center_angle = y\n",
    "                #print(shape(image))\n",
    "                \n",
    "                #img = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "                #img = img[:, :, 2] # choose S channel\n",
    "                #img = img.reshape(( img.shape[0], img.shape[1], 1))\n",
    "                \n",
    "                images.append(image)\n",
    "                angles.append(center_angle)\n",
    "\n",
    "            X_output = np.array(images)\n",
    "            y_output = np.array(angles)\n",
    "            #print(len(X_train))\n",
    "            # print(\"X_train: \", X_train)\n",
    "            # print(\"y_train: \", y_train)\n",
    "            yield shuffle(X_output, y_output)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(X_train, y_train, batch_size=240)\n",
    "#for x,y in generator(X_train, y_train, batch_size=32):\n",
    "#    print(y)\n",
    "validation_generator = generator(X_test, y_test, batch_size=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Dropout, ELU\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "print(\"X_train:\",len(X_train),\" y_train:\", len(y_train), \" X_test:\", len(X_test), \" y_test:\", len(y_test))\n",
    "\n",
    "model = Sequential()\n",
    "h,w,c=32,64,3\n",
    "#Preprocess\n",
    "model.add(Lambda(lambda x : x/255 - 0.5, input_shape = (160,320, 3)))\n",
    "model.add(Cropping2D(cropping = ((70, 25),(0,0))))\n",
    "\n",
    "model.add(Convolution2D(3, 1, 1, subsample=(1, 1), border_mode='same',\n",
    "                            init = 'he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(16, 5, 5, subsample=(4, 4), border_mode=\"same\",\n",
    "                            init = 'he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(32, 3, 3, subsample=(2, 2), border_mode=\"same\",\n",
    "                            init = 'he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU())\n",
    "model.add(Convolution2D(64, 3, 3, subsample=(2, 2), border_mode=\"same\", \n",
    "                            init = 'he_normal'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(.2))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(ELU())\n",
    "model.add(Dense(512))\n",
    "model.add(Dropout(.2)\n",
    "model.add(BatchNormalization())\n",
    "model.add(ELU())\n",
    "model.add(Dense(1))\n",
    "print(model.layers[-1].output_shape)\n",
    "#adam = Adam(lr=0.0001)\n",
    "model.compile(loss = 'mse', optimizer = 'adam')\n",
    "\n",
    "model.fit_generator(train_generator, \n",
    "                    samples_per_epoch=len(X_train), \n",
    "                    validation_data=validation_generator,\n",
    "                    nb_val_samples=len(X_test), nb_epoch=10)\n",
    "#model.fit(X_train, y_train, validation_split = 0.2, shuffle = True, nb_epoch=5)\n",
    "\n",
    "model.save(\"model.ib\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_object = model.fit_generator(train_generator, samples_per_epoch =\n",
    "    len(train_samples), validation_data = \n",
    "    validation_generator,\n",
    "    nb_val_samples = len(validation_samples), \n",
    "    nb_epoch=5, verbose=1)\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
